{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2404 sources from /Users/caganze/research/splat//resources/Spectra/Public/SPEX-PRISM/ to spectral database\n",
      "Adding 89 sources from /Users/caganze/research/splat//resources/Spectra/Public/MAGE/ to spectral database\n",
      "Adding 145 sources from /Users/caganze/research/splat//resources/Spectra/Public/LRIS-RED/ to spectral database\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/volumes/TOSHIBA/wispsdata/libraries//spex_data_set_table.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0f9b5276f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwisps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwisps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwispsim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/wisps/wisps/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#from .simulations.initialize import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#from .utils import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwisps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwisps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwisps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_sets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/wisps/wisps/data_analysis/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspectrum_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mphotometry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mselection_criteria\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/wisps/wisps/data_analysis/spectrum_tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_spt_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_sets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/wisps/wisps/data_sets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIBRARIES\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/spex_data_set_table.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#datasets['stars']=COMBINED_PHOTO_SPECTRO_DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#datasets['highsnr']=pd.read_pickle(LIBRARIES+'/highsnr_obejcts.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/volumes/TOSHIBA/wispsdata/libraries//spex_data_set_table.pkl'"
     ]
    }
   ],
   "source": [
    "import wisps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wisps.simulations as wispsim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import Normalize\n",
    "import astropy.units as u \n",
    "import wisps.simulations.effective_numbers as eff\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import popsims\n",
    "import itertools\n",
    "#plt.style.use('dark_background')\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import popsims\n",
    "import splat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrid=wispsim.SPGRID\n",
    "pnts=pd.read_pickle(wisps.OUTPUT_FILES+'/pointings_correctedf110.pkl')\n",
    "corr_pols=wisps.POLYNOMIAL_RELATIONS['mag_limit_corrections'] \n",
    "klf=pd.read_csv('/users/caganze/research/wisps/data/kirkpatricklf.txt', delimiter=',')\n",
    "klf['bin_center']=np.mean(np.array([klf.t0.values, klf.tf.values]), axis=0)\n",
    "klf=klf.replace(0.0,np.nan)\n",
    "\n",
    "cands=pd.read_pickle(wisps.LIBRARIES+'/real_ucds.pkl')\n",
    "cands=cands[(cands.spt >=17) & (cands.snr1>=3)].reset_index(drop=True)\n",
    "tab=wisps.Annotator.reformat_table(cands)\n",
    "pnt_names=[x.name for x in pnts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap= sns.color_palette(\"coolwarm\", 8, as_cmap=True)\n",
    "cmap=matplotlib.cm.get_cmap('coolwarm')\n",
    "cnorm=Normalize(wispsim.HS[0], (wispsim.HS[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kirkpatrick2020LF={'bin_center':np.flip(np.array([2025, 1875, 1725, 1575, 1425, 1275, 1125 , 975, 825, 675, 525])), \n",
    "                   'values':np.flip(np.array([0.72, 0.50,0.78, 0.81,0.94, 1.95, 1.11, 1.72, 1.99, 2.80, 4.24])), \n",
    "                   'unc':np.flip(([0.18, 0.17, 0.20,0.20, 0.22, 0.3, 0.25, 0.3, 0.32, 0.37, 0.70]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_by_spt_bin(sp_types, number, ltonly=False):\n",
    "    ranges=[[17, 20], [20, 25], [25, 30], [30, 35], [35, 40]]\n",
    "    if ltonly:\n",
    "        ranges=[[17, 20], [20, 30], [30, 41]]\n",
    "    numbers=[]\n",
    "    for r in ranges:\n",
    "        idx= np.logical_and((r[0]<=sp_types), (r[1]>sp_types))\n",
    "        numbers.append(np.nansum(number[idx]))\n",
    "    return numbers\n",
    "\n",
    "def get_all_numbers():\n",
    "    #Distribute the parameter sets evenly across the cores\n",
    "    func=lambda x, y:  get_simulated_number_model(y, x)\n",
    "\n",
    "    paramlist=[(i, j)  for i, j in itertools.product(['saumon2008', 'burrows2001', 'baraffe2003', 'marley2019', 'phillips2020'], wispsim.HS)]\n",
    "    res  = [func(x, y) for x,y in tqdm(paramlist)]\n",
    "    \n",
    "    nbrs = {}\n",
    "    for k in ['saumon2008', 'marley2019', 'phillips2020', 'burrows2001', 'baraffe2003']:\n",
    "        ds0={}\n",
    "        for j in res:\n",
    "            if k in j.keys():\n",
    "                key=[x for x in j[k].keys()][0]\n",
    "                ds0.update({key: [(j[k][key])[yi] for yi in wispsim.SPGRID]})\n",
    "        #print (ds0)\n",
    "        nbrs[k]=np.array([ds0[k] for k in wispsim.HS])\n",
    "\n",
    "    return nbrs\n",
    "    \n",
    "\n",
    "\n",
    "def get_pointing(grism_id):\n",
    "    if grism_id.startswith('par'):\n",
    "        pntname=grism_id.lower().split('-')[0]\n",
    "    else:\n",
    "        pntname=grism_id.lower().split('-g141')[0]\n",
    "    loc=pnt_names.index(pntname)\n",
    "    return np.array(pnts)[loc]\n",
    "\n",
    "\n",
    "def iswithin_mag_limits(mags, pnt, spt):\n",
    "    #mgs is a dictionary\n",
    "    flags=[]\n",
    "    for k in pnt.mag_limits.keys():\n",
    "        if k =='F110' and pnt.survey =='hst3d':\n",
    "            flags.append(True)\n",
    "        else:\n",
    "            flags.append(mags[k] <= pnt.mag_limits[k]+ (corr_pols[k+'W'][0])(spt))\n",
    "    return np.logical_or.reduce(flags)\n",
    "\n",
    "def scale_lf_teff(teffs):\n",
    "    binedges= np.append(kirkpatrick2020LF['bin_center']-75, kirkpatrick2020LF['bin_center'][-1]-75)\n",
    "    bools=np.logical_and(teffs <= binedges[-1], teffs >= binedges[0])\n",
    "    preds=np.histogram(teffs, bins=binedges, normed=False)[0]\n",
    "    \n",
    "    obs=np.array(kirkpatrick2020LF['values'])\n",
    "    unc=np.array(kirkpatrick2020LF['unc'])\n",
    "    \n",
    "    obs_monte_carlo= np.random.normal(obs, unc, (10000, len(obs)))\n",
    "    pred_monte= np.ones_like(obs_monte_carlo)*(preds)\n",
    "    unc_monte=  np.ones_like(obs_monte_carlo)*(unc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #unc_monte= \n",
    "    scale=(np.nansum((obs_monte_carlo*pred_monte)/(unc_monte**2), axis=1)\\\n",
    "           /np.nansum(((pred_monte**2)/(unc_monte**2)), axis=1))*(10**-3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #fig, ax=plt.subplots()\n",
    "    #ax.step(kirkpatrick2020LF['bin_centertw'], preds*scale*(10**-3), where='mid')\n",
    "    #x.errorbar(kirkpatrick2020LF['bin_center'], np.array(kirkpatrick2020LF['values'])*(10**-3),\n",
    "    #         yerr= np.array(kirkpatrick2020LF['unc'])*(10**-3), fmt='o', color='#111111')\n",
    "    return [np.nanmedian(scale), np.nanstd(scale), len(teffs)]\n",
    "def get_simulated_number_model(hidx, model):\n",
    "    #hidx is a scale height, model is evolutionary model\n",
    "    cutdf=pd.read_hdf(wisps.OUTPUT_FILES+'/final_simulated_sample_cut.h5', key=str(model)+str('h')+str(hidx)+'F110_corrected')\n",
    "    scl_dict=pd.read_pickle(wisps.OUTPUT_FILES+'/lf_scales.pkl') \n",
    "    scale=scl_dict[model]\n",
    "    #scale=scale_lf_teff(cutdf.teff)\n",
    "    NSIM=dict(zip(wispsim.SPGRID,np.zeros((len(wispsim.SPGRID), 2))))\n",
    "    cutdf['spt_r']=cutdf.spt.apply(np.round)\n",
    "    for g in cutdf.groupby('spt_r'):\n",
    "        sn= len(cutdf.teff[np.logical_and(cutdf.teff>=450, cutdf.teff<=1950)])\n",
    "        n0=scale[-1]/scale[0]\n",
    "        #print (n0)\n",
    "        scln=np.array([scale[0]*n0/sn,\\\n",
    "                       (scale[1]*scale[-1])/(sn*scale[0])])\n",
    "        #scln=np.array(scale)\n",
    "        #assert scln[0] > scale[0]\n",
    "        NSIM[g[0]]=np.nansum(g[1].sl)*scln\n",
    "    del cutdf\n",
    "    return {model: {hidx:NSIM}}\n",
    "\n",
    "\n",
    "def plot(NUMBERS, VOLUMES, filename='/oberved_numbers.pdf'):\n",
    "    # In[ ]:\n",
    "    nall=wisps.custom_histogram(cands.spt.apply(wisps.make_spt_number), sgrid, 1)\n",
    "    \n",
    "    y2=bin_by_spt_bin(wispsim.SPGRID,nobs, ltonly=False)-THICK\n",
    "    yall=bin_by_spt_bin(wispsim.SPGRID,nall, ltonly=False)\n",
    "    \n",
    "    dy2=np.sqrt(y2)\n",
    "    dyall=np.sqrt(yall)\n",
    "\n",
    "    fig, ax=plt.subplots(figsize=(14, 8), ncols=3, nrows=2, sharey=False, sharex=False)\n",
    "    \n",
    "    for model, a in zip(['burrows2001', 'baraffe2003', 'saumon2008', 'marley2019', 'phillips2020'], np.concatenate(ax)):\n",
    "        \n",
    "        for idx, h in enumerate(wispsim.HS):\n",
    "            \n",
    "            ns=None\n",
    "            ns=((NUMBERS[model])[idx])[:,0]*VOLUMES[idx]\n",
    "            nuncs=((NUMBERS[model])[idx])[:,1]*VOLUMES[idx]\n",
    "            \n",
    "            a.plot(spgrid2, bin_by_spt_bin(wispsim.SPGRID,ns, ltonly=False), \n",
    "                          color= cmap(cnorm(h)), \n",
    "                   linewidth=3, drawstyle=\"steps-mid\")\n",
    "            a.fill_between(spgrid2, bin_by_spt_bin(wispsim.SPGRID,ns+nuncs, ltonly=False),  \n",
    "                           bin_by_spt_bin(wispsim.SPGRID,ns-nuncs, ltonly=False), alpha=0.5, \n",
    "                           color= cmap(cnorm(h/100)),  step=\"mid\")\n",
    "        \n",
    "        a.set_yscale('log')\n",
    "        a.errorbar(spgrid2,y2, yerr=dy2,fmt='o', color='#111111')\n",
    "        a.errorbar(spgrid2,yall, yerr=dyall,color='#B10DC9', mfc='white', fmt='o')\n",
    "        a.set_xlabel('SpT',fontsize=18)\n",
    "        a.set_ylabel('N',fontsize=18)\n",
    "        a.minorticks_on()\n",
    "            \n",
    "\n",
    "\n",
    "   \n",
    "    ax[0][0].set_title('Model= B01', fontsize=18)\n",
    "    ax[0][1].set_title('Model= B03', fontsize=18)\n",
    "    ax[0][2].set_title('Model= SM08', fontsize=18)\n",
    "    ax[1][0].set_title('Model= M19', fontsize=18)\n",
    "    ax[1][1].set_title('Model= P20', fontsize=18)\n",
    "\n",
    "    ax[1][-2].errorbar(spgrid2,y2, yerr=dy2,fmt='o', label='Mag Limited', color='#111111')\n",
    "    ax[1][-2].errorbar(spgrid2,yall, yerr=dyall,color='#B10DC9', fmt='o', mfc='white', label='All Observations')\n",
    "    \n",
    "    #ax[-1][-2].legend(fontsize=14,  bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig.delaxes(np.concatenate(ax)[-1])\n",
    "    ax[1][-2].legend( fontsize=14)\n",
    "    \n",
    "    cax = fig.add_axes([.675, 0.3, .3, 0.03])\n",
    "    mp=matplotlib.cm.ScalarMappable(norm=cnorm, cmap='coolwarm')\n",
    "    cbar=plt.colorbar(mp, cax=cax, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(r'Scaleheight (H)', fontsize=18)\n",
    "    #cbar.ax.set_yticks([1, 3, 5, 10])\n",
    "    #np.concatenate(ax)[-2].legend(loc='center left', bbox_to_anchor=(1, 1.5), fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(wisps.OUTPUT_FIGURES+filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one(NUMBERS, VOLUMES, filename='/oberved_numbers_one_panel.pdf'):\n",
    "    data_to_save={}\n",
    "    # In[ ]:\n",
    "    nall=wisps.custom_histogram(cands.spt.apply(wisps.make_spt_number), sgrid, 1)\n",
    "    \n",
    "    y2=bin_by_spt_bin(wispsim.SPGRID,nobs, ltonly=False)-THICK\n",
    "    yall=bin_by_spt_bin(wispsim.SPGRID,nall, ltonly=False)-THICK\n",
    "    \n",
    "    dy2=np.sqrt(y2)\n",
    "    dyall=np.sqrt(yall)\n",
    "     #add this to the dictionary\n",
    "    data_to_save['nall']=nall\n",
    "    data_to_save['nobs']=nobs\n",
    "    data_to_save['yall']=yall\n",
    "    data_to_save['y2']=y2\n",
    "\n",
    "    fig, a=plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    #for model, a in zip(['baraffe2003', 'saumon2008', 'marley2019', 'phillips2020'], np.concatenate(ax)):\n",
    "    model='baraffe2003'\n",
    "    for idx, h in enumerate(wispsim.HS):\n",
    "            \n",
    "            ns=None\n",
    "            ns=((NUMBERS[model])[idx])[:,0]*VOLUMES[idx]\n",
    "            nuncs=((NUMBERS[model])[idx])[:,1]*VOLUMES[idx]\n",
    "            \n",
    "            a.plot(spgrid2, bin_by_spt_bin(wispsim.SPGRID,ns, ltonly=False), \n",
    "                          label='h={} pc'.format(h), color= cmap(cnorm(h/100)), \n",
    "                   linewidth=3, drawstyle=\"steps-mid\")\n",
    "            a.fill_between(spgrid2, bin_by_spt_bin(wispsim.SPGRID,ns+nuncs, ltonly=False),  \n",
    "                           bin_by_spt_bin(wispsim.SPGRID,ns-nuncs, ltonly=False), alpha=0.5, \n",
    "                           color= cmap(cnorm(h/100)),  step=\"mid\")\n",
    "            data_to_save.update({h: bin_by_spt_bin(wispsim.SPGRID,ns, ltonly=False)})\n",
    "        \n",
    "    a.set_yscale('log')\n",
    "    a.errorbar(spgrid2,y2, yerr=dy2,fmt='o', color='#111111')\n",
    "    a.errorbar(spgrid2,yall, yerr=dyall,color='#B10DC9', mfc='white', fmt='o')\n",
    "    a.set_xlabel('SpT',fontsize=18)\n",
    "    a.set_ylabel('N',fontsize=18)\n",
    "    a.minorticks_on()\n",
    "            \n",
    "\n",
    "    #a.set_title('Model= SM08', fontsize=18)\n",
    "    a.set_title('Model= B03', fontsize=18)\n",
    "    #a.set_title('Model= M19', fontsize=18)\n",
    "    #a.set_title('Model= P20', fontsize=18)\n",
    "\n",
    "    a.errorbar(spgrid2,y2, yerr=dy2,fmt='o', label='Mag Limited', color='#111111')\n",
    "    a.errorbar(spgrid2,yall, yerr=dyall,color='#B10DC9', fmt='o', mfc='white', label='All Observations')\n",
    "    \n",
    "    a.legend(fontsize=14, loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(wisps.OUTPUT_FIGURES+filename, bbox_inches='tight',  facecolor='white', transparent=False)\n",
    "    \n",
    "    import pickle\n",
    "    with open('/users/caganze/results.pkl', 'wb') as file:\n",
    "        pickle.dump(data_to_save,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d=pd.read_pickle(wisps.OUTPUT_FILES+'/distance_samples{}'.format(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expectted counts from thick disk\n",
    "THICK=np.array([8.79798048, 2.30571423, 0.14145726, 0.08853498, 0.01784511])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tab['pnt']=tab['grism_id'].apply(get_pointing)\n",
    "tab['spt_val']=np.vstack(tab.spt.values)[:,0]\n",
    "obsmgs=tab[['F140W', 'F110W', 'F160W']].rename(columns={\"F110W\": \"F110\", \n",
    "                                                                    \"F140W\": \"F140\",\n",
    "                                                                    \"F160W\": \"F160\"}).to_dict('records')\n",
    "\n",
    "flags=[iswithin_mag_limits(x, y, z) for x, y, z in zip(obsmgs, tab.pnt.values,tab.spt.values )]\n",
    "\n",
    "#let's see what happens if we include all objects\n",
    "#flags=np.ones(len(flags)).astype(bool)\n",
    "cdf_to_use=tab[flags]\n",
    "\n",
    "nobs=wisps.custom_histogram(cdf_to_use.spt_val.apply(wisps.make_spt_number), sgrid, 1)\n",
    "\n",
    "\n",
    "spgrid2=['M7-L0', 'L0-L5', 'L5-T0', 'T0-T5', 'T5-Y0']\n",
    "spgrid3=['Late M', 'L', 'T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['F140', 'F110', 'F160']:\n",
    "    tab['lim_{}'.format(k)]=tab.pnt.apply(lambda x: x.mag_limits[k])\n",
    "    tab['detected_{}'.format(k)]= tab[k+'W'] < tab['lim_{}'.format(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtab=(tab[tab.spt.between(30, 35)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print( subtab[['F140W', 'F160W', 'lim_F140', 'lim_F160', 'detected_F140', 'detected_F160', 'grism_id',\n",
    "#                  'spt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBERS=pd.read_pickle(wisps.OUTPUT_FILES+'/numbers_simulated.pkl')\n",
    "NUMBERS=get_all_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(np.log10(NUMBERS['baraffe2003'][0][:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes=[]\n",
    "for pnt in pnts:\n",
    "    vs=[]\n",
    "    for h in wispsim.HS:\n",
    "        vsx=[]\n",
    "        for g in wispsim.SPGRID:\n",
    "            vsx.append((pnt.volumes[h])[g])\n",
    "        vs.append(vsx)\n",
    "    volumes.append(vs)\n",
    "volumes=np.array(volumes)\n",
    "\n",
    "VOLUMES=(np.nansum(volumes, axis=0))*4.1*(u.arcmin**2).to(u.radian**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " plot(NUMBERS, VOLUMES, filename='/obs_numbers.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_one(NUMBERS, VOLUMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nall=wisps.custom_histogram(cands.spt.apply(wisps.make_spt_number), sgrid, 1)\n",
    "y2=bin_by_spt_bin(wispsim.SPGRID,nobs, ltonly=False)-THICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymetric_errors(vals):\n",
    "    if len(vals)<1:\n",
    "        return [np.nan, np.nan]\n",
    "    else:\n",
    "        med= np.nanmedian(vals)\n",
    "        up= np.nanpercentile(vals, 86)\n",
    "        dn= np.nanpercentile(vals, 14)\n",
    "        return np.array([med-dn, up-med])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile(wispsim.HS, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bin_by_spt_bin(wispsim.SPGRID,NUMBERS['baraffe2003'][-1][:,0]*VOLUMES[-1]*(0.12/0.8)))\n",
    "plt.plot(THICK)\n",
    "#THICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin_by_spt_bin(wispsim.SPGRID,nall, ltonly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for L dwarfs and T dwarfs\n",
    "y3=bin_by_spt_bin(wispsim.SPGRID,nall, ltonly=False)-THICK\n",
    "y4=bin_by_spt_bin(wispsim.SPGRID,nobs, ltonly=True)#-THICK\n",
    "y5= np.nansum(y4)\n",
    "print ('all ----- {}'.format(y3))\n",
    "print ('used ----- {}'.format(y2))\n",
    "print ('MLT ----{}'.format(y4))\n",
    "print ('All ----{}'.format(y5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINT THE BEST FIT NUMBER \n",
    "#best_fit={}\n",
    "numbers_fit={} #predictions for all\n",
    "numbers_fit_lt={} #predictions for M, L, T\n",
    "#numbers_fit_total={} #predictions for total number counts\n",
    "for model in ['burrows2001', 'saumon2008', 'baraffe2003', 'marley2019', 'phillips2020']:\n",
    "        model_number_lt={}\n",
    "        model_number={}\n",
    "        for idx, h in enumerate(wispsim.HS):\n",
    "            \n",
    "            ns=None\n",
    "            ns=((NUMBERS[model])[idx])[:,0]*VOLUMES[idx]\n",
    "            nuncs=((NUMBERS[model])[idx])[:,1]*VOLUMES[idx]\n",
    "            \n",
    "            binned=np.array(bin_by_spt_bin(wispsim.SPGRID,ns, ltonly=False))\n",
    "            binned_lt= np.array(bin_by_spt_bin(wispsim.SPGRID,ns, ltonly=True))\n",
    "            #binned_unc=np.array(bin_by_spt_bin(wispsim.SPGRID,nuncs, ltonly=False))\n",
    "            #add L and \n",
    "            #compute chi-squared\n",
    "            #print (ns)\n",
    "            #chisq= abs((y2-binned)**2/(y2))\n",
    "            #model_fit.update({h: chisq})\n",
    "            #binned_total=np.append(binned, binned_lt)\n",
    "            #binned_total=np.append(binned, binned_lt)\n",
    "            model_number.update({h: binned})\n",
    "            model_number_lt.update({h: binned_lt})\n",
    "        # best_fit.update({model: model_fit})\n",
    "        numbers_fit.update({model: model_number})\n",
    "        numbers_fit_lt.update({model:  model_number_lt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chisq_dicts=pd.DataFrame.from_records(best_fit)\n",
    "pred_number_dicts=pd.DataFrame.from_records(numbers_fit)\n",
    "pred_number_lt_dicts=pd.DataFrame.from_records(numbers_fit_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_poisson_predictions(spt_grid, obstns, predns):\n",
    "    res={}\n",
    "    for c in  predns.columns:\n",
    "        min_vals={}\n",
    "        dist={}\n",
    "        #for idx,s  in enumerate(np.append(spgrid2, ['L dwarfs', 'T dwarfs'])):\n",
    "        for idx,s  in enumerate(spt_grid):\n",
    "            #compare between subtypes\n",
    "            #predicted\n",
    "            predvals=(np.vstack(predns[c].values))[:,idx]\n",
    "            #observed\n",
    "            nreal=  obstns[idx]\n",
    "            #make an interpolation function\n",
    "            #interpf = interp1d(predvals, wispsim.HS)\n",
    "            #using a 2nd degree polynomial \n",
    "            interpf = np.poly1d(np.polyfit(predvals, wispsim.HS, 3))\n",
    "\n",
    "            #draw a bunch of random values based on a poisson distribution\n",
    "            #npoisson=np.random.poisson(nreal, 100000).astype(float)\n",
    "            #print (nreal)\n",
    "            npoisson=stats.gamma.rvs(nreal, size =int(1e5))\n",
    "            #stay within the range of possible values to avoid interpolation error\n",
    "            #i.e take this as a prior\n",
    "            #dflag=npoisson>=vals.min()\n",
    "            #uflag= npoisson <=vals.max()\n",
    "            #npoisson[dflag]= vals.min()\n",
    "            #npoisson[uflag]= vals.max()\n",
    "            #allow extraploayion\n",
    "            npoisson=npoisson[np.logical_and(npoisson>=predvals.min(), npoisson <=predvals.max())]\n",
    "            #predict scale heights\n",
    "            predhs=interpf(npoisson)\n",
    "            #use a weighted mean and std \n",
    "            #mean, unc= (np.nanmean(predhs), np.nanstd(predhs))\n",
    "\n",
    "            #print (' scale height for model {} and spt {} is {} +/- {} '.format(c, s, np.round(mean), np.round(unc, 4)))\n",
    "            dist.update({s:predhs})\n",
    "        #min_chi_ssqrs.update({c:min_vals})\n",
    "        res.update({c: dist})\n",
    "    return  res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleheight_to_vertical_disp(hs):\n",
    "    shape=435 #shape parameter\n",
    "    sigma_68=1.\n",
    "    return np.sqrt((np.array(hs))/shape)*20\n",
    "\n",
    "def compute_age_with_z(sigmas, z):\n",
    "    ag_bov= popsims.avr_yu(sigmas[abs(z) >270], verbose=True, nsample=2, height='above')[0]\n",
    "    ag_bel=popsims.avr_yu(sigmas[abs(z) <=270], verbose=True, nsample=2, height='below')[0]\n",
    "    return np.concatenate([ag_bov, ag_bel]).flatten()\n",
    "\n",
    "def asssymetric_med_std(x):\n",
    "    return np.round(np.nanmedian(x), 2), np.round(asymetric_errors(x), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avr_aumer(sigma,  direction='vertical', verbose=False):\n",
    "    #return the age from an age-velocity dispersion \n",
    "    verboseprint = print if verbose else lambda *a, **k: None\n",
    "    result=None\n",
    "    beta_dict={'radial': [0.307, 0.001, 41.899],\n",
    "                'total': [ 0.385, 0.261, 57.15747],\n",
    "                'azimuthal':[0.430, 0.715, 28.823],\n",
    "                'vertical':[0.445, 0.001, 23.831],\n",
    "                }\n",
    "\n",
    "    verboseprint(\"Assuming Aumer & Binney 2009 Metal-Rich Fits and {} velocity \".format(direction))\n",
    "\n",
    "    beta, tau1, sigma10=beta_dict[direction]\n",
    "       \n",
    "    result=((sigma/sigma10)**(1/beta))*(10+tau1)-tau1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(106.20201952)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_height_dist=get_poisson_predictions(spgrid2, y2,pred_number_dicts)\n",
    "scale_height_dist_df=pd.DataFrame(scale_height_dist)\n",
    "vel_df=scale_height_dist_df.applymap(scaleheight_to_vertical_disp)\n",
    "age_distdf_yu=vel_df.applymap(lambda x: popsims.avr_yu(x, verbose=False, nsample=2, height='median')[0])\n",
    "age_distdf_just=vel_df.applymap(lambda x: popsims.avr_just(x, verbose=False))\n",
    "age_distdf_sand=vel_df.applymap(lambda x: popsims.avr_sanders(x, verbose=False))\n",
    "age_distdf_aumer=vel_df.applymap(lambda x: avr_aumer(x, verbose=False))\n",
    "\n",
    "\n",
    "\n",
    "scalh_tables=scale_height_dist_df.applymap( asssymetric_med_std)\n",
    "vel_tables=vel_df.applymap(asssymetric_med_std)\n",
    "age_tables_yu=age_distdf_yu.applymap( asssymetric_med_std)\n",
    "age_tables_just=age_distdf_just.applymap( asssymetric_med_std)\n",
    "age_tables_sand=age_distdf_sand.applymap( asssymetric_med_std)\n",
    "age_tables_aumer=age_distdf_aumer.applymap( asssymetric_med_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.vstack(pred_number_dicts['baraffe2003'].values))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obstns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.arange(len(y2)):\n",
    "    predvals=(np.vstack(np.vstack(pred_number_dicts['baraffe2003'].values)))[:,idx]\n",
    "    #observed\n",
    "\n",
    "    #make an interpolation function\n",
    "    interpf = np.poly1d(np.polyfit(predvals, wispsim.HS, 3))\n",
    "    #interpf =interp1d(predvals, wispsim.HS)\n",
    "    \n",
    "    rvs=stats.gamma.rvs(y2[idx], size =int(1e5))\n",
    "    rvs=rvs[np.logical_and(rvs>=predvals.min(), rvs <=predvals.max())]\n",
    "    fig, ax=plt.subplots()\n",
    "    plt.scatter( wispsim.HS, predvals, marker='^', color='k')\n",
    "    plt.plot( interpf(rvs), rvs, '.')\n",
    "    plt.axhline(y2[idx], color='r')\n",
    "    #h=plt.hist(rvs, bins='auto')\n",
    "    fig, ax=plt.subplots()\n",
    "    h=plt.hist(interpf(rvs), bins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalh_tables[['baraffe2003', 'saumon2008', 'marley2019', 'phillips2020']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(val):\n",
    "    return str(val[0])+'$ _{-'+str(val[1][0])+'} ^{+'+str(val[1][1])+'}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalh_tables[['burrows2001', 'baraffe2003', 'saumon2008', \\\n",
    "              'marley2019', 'phillips2020']].applymap(reformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_tables[['burrows2001', 'baraffe2003', 'saumon2008', 'marley2019', 'phillips2020']].applymap(reformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_tables_just[['burrows2001', 'baraffe2003', 'saumon2008', 'marley2019', 'phillips2020']].applymap(reformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper and lo limits on ages \n",
    "#up_lims_table=pd.DataFrame(columns= age_tables.columns,\n",
    "#                           index=age_tables.index).fillna(0)\n",
    "#up_lims_table.saumon2008['T0-T5']=1\n",
    "#up_lims_table.saumon2008['T0-T5']=1\n",
    "\n",
    "#lo limts\n",
    "#lo_lims_table=pd.DataFrame(columns= age_tables.columns,\n",
    "#                           index=age_tables.index).fillna(0)\n",
    "#lo_lims_table.baraffe2003['T5-Y0']=1\n",
    "#lo_lims_table.baraffe2003['L5-T0']=1\n",
    "#lo_lims_table.phillips2020['T5-Y0']=1\n",
    "#lo_lims_table.saumon2008['T5-Y0']=1\n",
    "#lo_lims_table.marley2019['T5-Y0']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simpler_class(x):\n",
    "    if x.startswith('M'):\n",
    "        return 'Late M'\n",
    "    if x.startswith('L'):\n",
    "        return 'L'\n",
    "    if x.startswith('T'):\n",
    "        return 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot age with scale heights\n",
    "age_dictionaries={}\n",
    "for model in ['burrows2001', 'saumon2008', 'baraffe2003', 'marley2019', 'phillips2020']:\n",
    "    dfs=[]\n",
    "    for hidx in wispsim.HS:\n",
    "        dfs.append(pd.read_hdf(wisps.OUTPUT_FILES+'/final_simulated_sample_cut.h5',\n",
    "                               key=str(model)+str('h')+str(hidx)+'F110_corrected'))\n",
    "        \n",
    "    df=pd.concat(dfs)\n",
    "    print (len(df))\n",
    "    cutdf_lblded=wisps.Annotator.group_by_spt(df, spt_label='spt', assign_number=False).rename(columns={'spt_range': 'subtype'})\n",
    "    cutdf_lblded['spectclass']=  cutdf_lblded.subtype.apply(get_simpler_class)\n",
    "    final_df=cutdf_lblded[~((cutdf_lblded.spectclass=='') | (cutdf_lblded.subtype=='')|   (cutdf_lblded.subtype=='trash'))]\n",
    "    age_dictionaries[model]=final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.errorbar(  agfn.age, agfn.subtype, xerr=np.vstack(agfn.unc).T,  fmt='o',xlolims=lolims, ms=20, lw=7, \n",
    "#               capsize=7, \n",
    "#               mfc='#0074D9', mec='#111111', ecolor='#111111', xuplims=uplims)\n",
    "#age_dictionaries[model].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_age():\n",
    "    model='baraffe2003'\n",
    "    ds=[]\n",
    "    fig, a=plt.subplots()\n",
    "    dfn=age_dictionaries[model].replace('T5-T9', 'T5-Y0')\n",
    "    for k in age_tables_just[model].keys():\n",
    "        if len(scale_height_dist[model][k]) <1:\n",
    "            pass\n",
    "        else:\n",
    "            #empirical\n",
    "            #ds0.append(age_tables_just[model][k])\n",
    "            #from simulations\n",
    "            ds.append(dfn.age[dfn.subtype==k].values)\n",
    "    #some reformatting\n",
    "\n",
    "    positions=[0, 1, 2, 3, 4]\n",
    "    lolims=[0, 0, 0, 0, 0]\n",
    "    if len(ds) ==4: positions=[1, 2, 3, 4]\n",
    "    v1 = a.violinplot(ds,points=100, positions=positions,\n",
    "               showmeans=True, showextrema=False, showmedians=False, vert =False)\n",
    "    for b in v1['bodies']: \n",
    "          b.set_color('#0074D9')\n",
    "        #get the center\n",
    "    xerr0=np.vstack((age_tables_just[model].apply(lambda x: x[1]).values)).T\n",
    "    xerr1=np.vstack((age_tables_sand[model].apply(lambda x: x[1]).values)).T\n",
    "    xerr2=np.vstack((age_tables_aumer[model].apply(lambda x: x[1]).values)).T\n",
    "    \n",
    "    #set size of arrows\n",
    "    xerr0.T[np.array(lolims).astype(bool)]=[0.5, 0.5]\n",
    "    xerr1.T[np.array(lolims).astype(bool)]=[0.5, 0.5]\n",
    "    xerr2.T[np.array(lolims).astype(bool)]=[0.5, 0.5]\n",
    "    \n",
    "    a.errorbar(age_tables_just[model].apply(lambda x: x[0]).values, [0, 1, 2, 3, 4],\\\n",
    "               xerr=xerr0,  fmt='o', label='J10', \\\n",
    "              ms=10, lw=5,  mfc='#B10DC9', mec='#B10DC9', ecolor='#B10DC9', capsize=5,\n",
    "               xlolims=lolims)\n",
    "    \n",
    "    #a.errorbar(age_tables_yu[model].apply(lambda x: x[0]).values,  np.array([0, 1, 2, 3, 4])+0.2,\\\n",
    "    #           xerr=np.vstack((age_tables_yu[model].apply(lambda x: x[1]).values)).T,  fmt='o', label='Y18',\n",
    "    #           ms=10, lw=5,  mfc='#B10DC9', mec='#B10DC9', ecolor='#B10DC9', capsize=5)\n",
    "    \n",
    "    #a.errorbar(age_tables_sand[model].apply(lambda x: x[0]).values,  np.array([0, 1, 2, 3, 4])+0.0,\\\n",
    "    #           xerr=xerr1,  fmt='o', label='SB15',\n",
    "    #           ms=10, lw=5,  mfc='#B10DC9', mec='#B10DC9', ecolor='#B10DC9', capsize=5,\n",
    "    #            xlolims=lolims)\n",
    "    \n",
    "    a.errorbar(age_tables_aumer[model].apply(lambda x: x[0]).values,  np.array([0, 1, 2, 3, 4])+0.30,\\\n",
    "               xerr=xerr2,  fmt='o', label='AB09',\n",
    "               ms=10, lw=5,  mfc='#111111', mec='#111111', ecolor='#111111', capsize=5,\n",
    "                xlolims=lolims)\n",
    "    \n",
    "    a.set_yticks([0, 1, 2, 3, 4])\n",
    "    a.set_yticklabels(spgrid2)\n",
    "    a.set_xlabel('Age (Gyr)', fontsize=18)\n",
    "    a.set_ylabel('Subtype', fontsize=18)\n",
    "    a.minorticks_on()\n",
    "    a.set_xlim([-1, 20])\n",
    "    a.set_title('Model= B03', fontsize=18)\n",
    "    a.legend(fontsize=12, loc='lower left')\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(wisps.OUTPUT_FIGURES+'/age_comparison_one.pdf', bbox_inches='tight',  \\\n",
    "                facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(12, 8), ncols=3, nrows=2, sharex=False, sharey=True)\n",
    "for model, a in zip(['burrows2001', 'baraffe2003', 'saumon2008','marley2019', 'phillips2020'], np.concatenate(ax)):\n",
    "\n",
    "    ds=[]\n",
    "    \n",
    "    dfn=age_dictionaries[model].replace('T5-T9', 'T5-Y0')\n",
    "    for k in age_tables_just[model].keys():\n",
    "        if len(scale_height_dist[model][k]) <1:\n",
    "            pass\n",
    "        else:\n",
    "            #empirical\n",
    "            #ds0.append(age_tables_just[model][k])\n",
    "            #from simulations\n",
    "            ds.append(dfn.age[dfn.subtype==k].values)\n",
    "    #some reformatting\n",
    "\n",
    "    positions=[0, 1, 2, 3, 4]\n",
    "    lolims=[0, 0, 0, 0, 0]\n",
    "    if len(ds) ==4: positions=[1, 2, 3, 4]\n",
    "    v1 = a.violinplot(ds,points=100, positions=positions,\n",
    "               showmeans=True, showextrema=False, showmedians=False, vert =False)\n",
    "    for b in v1['bodies']: \n",
    "          b.set_color('#0074D9')\n",
    "        #get the center\n",
    "    xerr0=np.vstack((age_tables_just[model].apply(lambda x: x[1]).values)).T\n",
    "    xerr1=np.vstack((age_tables_sand[model].apply(lambda x: x[1]).values)).T\n",
    "    xerr2=np.vstack((age_tables_aumer[model].apply(lambda x: x[1]).values)).T\n",
    "    \n",
    "    #set size of arrows\n",
    "    xerr0.T[np.array(lolims).astype(bool)]=[0.5, 0.5]\n",
    "    xerr1.T[np.array(lolims).astype(bool)]=[0.5, 0.5]\n",
    "    xerr2.T[np.array(lolims).astype(bool)]=[0.5, 0.5]\n",
    "    \n",
    "    a.errorbar(age_tables_just[model].apply(lambda x: x[0]).values, [0, 1, 2, 3, 4],\\\n",
    "               xerr=xerr0,  fmt='o', label='J10', \\\n",
    "              ms=10, lw=5,  mfc='#B10DC9', mec='#B10DC9', ecolor='#B10DC9', capsize=5,\n",
    "               xlolims=lolims)\n",
    "    \n",
    "    #a.errorbar(age_tables_yu[model].apply(lambda x: x[0]).values,  np.array([0, 1, 2, 3, 4])+0.2,\\\n",
    "    #           xerr=np.vstack((age_tables_yu[model].apply(lambda x: x[1]).values)).T,  fmt='o', label='Y18',\n",
    "    #           ms=10, lw=5,  mfc='#B10DC9', mec='#B10DC9', ecolor='#B10DC9', capsize=5)\n",
    "    \n",
    "    #a.errorbar(age_tables_sand[model].apply(lambda x: x[0]).values,  np.array([0, 1, 2, 3, 4])+0.0,\\\n",
    "    #           xerr=xerr1,  fmt='o', label='SB15',\n",
    "    #           ms=10, lw=5,  mfc='#B10DC9', mec='#B10DC9', ecolor='#B10DC9', capsize=5,\n",
    "    #            xlolims=lolims)\n",
    "    \n",
    "    a.errorbar(age_tables_aumer[model].apply(lambda x: x[0]).values,  np.array([0, 1, 2, 3, 4])+0.30,\\\n",
    "               xerr=xerr2,  fmt='o', label='AB09',\n",
    "               ms=10, lw=5,  mfc='#111111', mec='#111111', ecolor='#111111', capsize=5,\n",
    "                xlolims=lolims)\n",
    "    \n",
    "    a.set_yticks([0, 1, 2, 3, 4])\n",
    "    a.set_yticklabels(spgrid2)\n",
    "    a.set_xlabel('Age (Gyr)', fontsize=18)\n",
    "    a.set_ylabel('Subtype', fontsize=18)\n",
    "    a.minorticks_on()\n",
    "    a.set_xlim([-1, 12])\n",
    "    a.set_ylim([-1, 5])\n",
    "    \n",
    "ax[0][0].set_xlim([-1, 20])\n",
    "ax[0][0].set_title('Model= B03', fontsize=18)\n",
    "ax[0][1].set_title('Model= SM08', fontsize=18)\n",
    "ax[1][0].set_title('Model= M19', fontsize=18)\n",
    "ax[1][1].set_title('Model= P20', fontsize=18)\n",
    "ax[1][-2].legend(fontsize=12, loc='lower left')\n",
    "fig.delaxes(np.concatenate(ax)[-1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(wisps.OUTPUT_FIGURES+'/age_comparison.pdf', bbox_inches='tight',  \\\n",
    "            facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(12, 8), ncols=3, nrows=2, sharex=False, sharey=True)\n",
    "\n",
    "for model, a in zip([ 'burrows2001', 'baraffe2003', 'saumon2008','marley2019', 'phillips2020'], np.concatenate(ax)):\n",
    "    ds=[]\n",
    "    for k in scale_height_dist[model].keys():\n",
    "        if len(scale_height_dist[model][k]) <1:\n",
    "            pass\n",
    "        else:\n",
    "            ds.append(scale_height_dist[model][k])\n",
    "\n",
    "    positions=[0, 1, 2, 3, 4]\n",
    "    if len(ds) ==4: positions=[1, 2, 3, 4]\n",
    "    v1 = a.violinplot(ds,points=300, positions=positions,\n",
    "               showmeans=False, showmedians=True, showextrema=False, vert =False)\n",
    "    for b in v1['bodies']: \n",
    "          b.set_color('#FF4136')\n",
    "        #get the center\n",
    "    a.set_yticks([0, 1, 2, 3, 4])\n",
    "    a.set_yticklabels(spgrid2)\n",
    "    a.set_xlabel('H (pc)', fontsize=18)\n",
    "    a.set_ylabel('Subtype', fontsize=18)\n",
    "    a.minorticks_on()\n",
    "\n",
    "ax[0][0].set_title('Model= B01', fontsize=18)\n",
    "ax[0][1].set_title('Model= B03', fontsize=18)\n",
    "ax[0][2].set_title('Model= SM08', fontsize=18)\n",
    "ax[1][0].set_title('Model= M19', fontsize=18)\n",
    "ax[1][1].set_title('Model= P20', fontsize=18)\n",
    "\n",
    "fig.delaxes(np.concatenate(ax)[-1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(wisps.OUTPUT_FIGURES+'/scaleheight_comparison.pdf', bbox_inches='tight',  \\\n",
    "            facecolor='white', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex-readble \n",
    "#plt.hist(vel_df[model]['T0-T5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisps.drop_nan(vel_df[model][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(12, 8), ncols=3, nrows=2, sharex=False, sharey=True)\n",
    "for model, a in zip(['burrows2001', 'baraffe2003', 'saumon2008','marley2019', 'phillips2020'], np.concatenate(ax)):\n",
    "    ds=[]\n",
    "    for k in vel_df[model].keys():\n",
    "        if len(vel_df[model][k]) <1:\n",
    "            pass\n",
    "        else:\n",
    "            ds.append(wisps.drop_nan(vel_df[model][k]))\n",
    "\n",
    "    positions=[0, 1, 2, 3, 4]\n",
    "    if len(ds) ==4: positions=[1, 2, 3, 4]\n",
    "    v1 = a.violinplot(ds, points=100, positions=positions,\n",
    "               showmeans=False, showextrema=False, showmedians=True, vert =False)\n",
    "    for b in v1['bodies']: \n",
    "          b.set_color('#FF4136')\n",
    "        #get the center\n",
    "    a.set_yticks([0, 1, 2, 3, 4])\n",
    "    a.set_yticklabels(spgrid2)\n",
    "    a.set_xlabel(r'$\\sigma _w$ (km/s)', fontsize=18)\n",
    "    a.set_ylabel('Subtype', fontsize=18)\n",
    "    a.minorticks_on()\n",
    "    \n",
    "ax[0][0].set_title('Model= B01', fontsize=18)\n",
    "ax[0][1].set_title('Model= SM08', fontsize=18)\n",
    "ax[0][2].set_title('Model= SM08', fontsize=18)\n",
    "ax[1][0].set_title('Model= M19', fontsize=18)\n",
    "ax[1][1].set_title('Model= P20', fontsize=18)\n",
    "fig.delaxes(np.concatenate(ax)[-1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(wisps.OUTPUT_FIGURES+'/velocity_comparison.pdf', bbox_inches='tight',  \\\n",
    "            facecolor='white', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(12, 12), ncols=2, nrows=2, sharex=False, sharey=True)\n",
    "for model, a in zip([ 'baraffe2003', 'saumon2008','marley2019', 'phillips2020'], np.concatenate(ax)):\n",
    "    ds=[]\n",
    "    ds1=[]\n",
    "    for k in vel_df[model].keys():\n",
    "        if len(age_distdf_aumer[model][k]) <1:\n",
    "            pass\n",
    "        else:\n",
    "            ds.append(age_distdf_aumer[model][k])\n",
    "            ds1.append(age_distdf_just[model][k])\n",
    "\n",
    "    positions=[0, 1, 2, 3, 4]\n",
    "    if len(ds) ==4: positions=[1, 2, 3, 4]\n",
    "    v1 = a.violinplot(ds,points=100, positions=positions,\n",
    "               showmeans=True, showextrema=False, showmedians=False, vert =False)\n",
    "    v2 = a.violinplot(ds1,points=100, positions=positions,\n",
    "               showmeans=True, showextrema=False, showmedians=False, vert =False)\n",
    "    for b in v1['bodies']: \n",
    "          b.set_color('#FF4136')\n",
    "    for b in v2['bodies']: \n",
    "          b.set_color('#0074D9')\n",
    "        #get the center\n",
    "    a.set_yticks([0, 1, 2, 3, 4])\n",
    "    a.set_yticklabels(spgrid2)\n",
    "    a.set_xlabel(r'Age (Gyr)', fontsize=18)\n",
    "    a.set_ylabel('Subtype', fontsize=18)\n",
    "    a.minorticks_on()\n",
    "ax[0][0].set_title('Model= B03', fontsize=18)\n",
    "ax[0][1].set_title('Model= SM08', fontsize=18)\n",
    "ax[1][0].set_title('Model= M19', fontsize=18)\n",
    "ax[1][1].set_title('Model= P20', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(wisps.OUTPUT_FIGURES+'/age_empirical_comparison.pdf', bbox_inches='tight',  \\\n",
    "            facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.violinplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_height_dist_df.apply(lambda x: np.concatenate(x.values), axis=0).apply(lambda x: \\\n",
    "#                            (np.nanmedian(x), \n",
    "#                            np.nanstd(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalh_tables.loc['M7-L0']['baraffe2003'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, unc=asssymetric_med_std(np.concatenate(scale_height_dist_df.loc['M7-L0'].values).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(df, subtype, rund=1):\n",
    "    vs=np.concatenate(df.loc[subtype].values).flatten()\n",
    "    val, unc=asssymetric_med_std(vs)\n",
    "    res=''\n",
    "    if np.isnan(val):\n",
    "            res += ''\n",
    "    else:\n",
    "        if rund <1:\n",
    "                st=str(int(np.round(val, rund)))+ '$_{-'+ str(int(np.round(unc[0], rund)))+'}'+\\\n",
    "                '^{+'+str(int(np.round(unc[1], rund)))+'} $&'\n",
    "        else:\n",
    "                st=str(np.round(val, rund))+ '$_{-'+ str(np.round(unc[0], rund))+'}'+\\\n",
    "                '^{+'+str(np.round(unc[1], rund))+'} $&'\n",
    "        res += st\n",
    "    \n",
    "    return res\n",
    "def get_formatted_string(df, subtype, rund=1):\n",
    "    dn=df.loc[subtype]\n",
    "    res=''\n",
    "    for md in ['burrows2001', 'baraffe2003', 'saumon2008', 'marley2019', 'phillips2020' ]:\n",
    "        val= dn[md][0]\n",
    "        unc=dn[md][1]\n",
    "        if np.isnan(val):\n",
    "            res += '&'\n",
    "        else:\n",
    "            if rund <1:\n",
    "                st=str(int(np.round(val, rund)))+ '$_{-'+ str(int(np.round(unc[0], rund)))+'}'+\\\n",
    "                '^{+'+str(int(np.round(unc[1], rund)))+'} $&'\n",
    "            else:\n",
    "                st=str(np.round(val, rund))+ '$_{-'+ str(np.round(unc[0], rund))+'}'+\\\n",
    "                '^{+'+str(np.round(unc[1], rund))+'} $&'\n",
    "            res += st\n",
    "    return res\n",
    "\n",
    "def get_age_median_from_simulation(subtype, rund=1):\n",
    "    res=''\n",
    "    for model in ['burrows2001', 'baraffe2003', 'saumon2008', 'marley2019', 'phillips2020' ]:\n",
    "        dfn0=age_dictionaries[model].replace('T5-T9', 'T5-Y0')\n",
    "        dfn=dfn0[dfn0.subtype==subtype]\n",
    "        if len(scale_height_dist[model][subtype]) <1:\n",
    "            res += '&'\n",
    "        else:\n",
    "            val, unc= asssymetric_med_std(dfn['age'].values)\n",
    "            if rund <1:\n",
    "                st=str(int(np.round(val, rund)))+ '$_{-'+ str(int(np.round(unc[0], rund)))+'}'+\\\n",
    "                '^{+'+str(int(np.round(unc[1], rund)))+'} $&'\n",
    "            else:\n",
    "                st=str(np.round(val, rund))+ '$_{-'+ str(np.round(unc[0], rund))+'}'+\\\n",
    "                '^{+'+str(np.round(unc[1], rund))+'} $&'\n",
    "            res += st\n",
    "    return res\n",
    "\n",
    "def get_age_median_all_from_simulation(subtype, rund=1):\n",
    "    ds=[]\n",
    "    res=''\n",
    "    for model in ['burrows2001', 'baraffe2003', 'saumon2008', 'marley2019', 'phillips2020' ]:\n",
    "        dfn0=age_dictionaries[model].replace('T5-T9', 'T5-Y0')\n",
    "        ds.append(dfn0[dfn0.subtype==subtype].age.values)\n",
    "    val, unc=asssymetric_med_std(np.concatenate(ds))\n",
    "    st=str(np.round(val, rund))+ '$_{-'+ str(np.round(unc[0], rund))+'}'+\\\n",
    "                '^{+'+str(np.round(unc[1], rund))+'} $&'\n",
    "    res += st\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_median_from_simulation(subtype, rund=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_age_median_all_from_simulation(subtype, rund=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_median(age_dictionaries['burrows2001'], subtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print latex formatted \n",
    "for idx, subtype in enumerate(spgrid2):\n",
    "    print (subtype + r'&$H$ (pc) &' + get_formatted_string(scalh_tables, subtype, rund=0) \\\n",
    "           + get_median(scale_height_dist_df, subtype, rund=0) + '&'+ \\\n",
    "           str(int(np.round(y2)[idx]))+ r'\\\\ ')\n",
    "    print (r' & $\\sigma_w$ (km/s)  &' + get_formatted_string(vel_tables, subtype) \\\n",
    "           + get_median(vel_df, subtype) + '&'+ r'\\\\ ')\n",
    "    print (r' & Age (Gyr) (J10) &' + get_formatted_string(age_tables_just, subtype) \\\n",
    "           + get_median(age_distdf_just, subtype)+ '&' + r'\\\\ ')\n",
    "    #print (r' & Age (Gyr) (SB15)&' + get_formatted_string(age_tables_sand, subtype)  \\\n",
    "    #       + get_median(age_distdf_sand, subtype) + r'\\\\ ')\n",
    "    #print (r' & Age (Gyr) (Y18)&' + get_formatted_string(age_tables_yu, subtype)  \\\n",
    "    #       + get_median(age_distdf_yu, subtype) + r'\\\\ ')\n",
    "    print (r' & Age (Gyr) (A09)&' + get_formatted_string(age_tables_aumer, subtype)  \\\n",
    "           + get_median(age_distdf_aumer, subtype)+ '&' + r'\\\\ ')\n",
    "    \n",
    "    print (r' & Age (Gyr) (Simulation)&' + get_median_from_simulation(subtype, rund=1)  \\\n",
    "           + get_age_median_all_from_simulation(subtype, rund=1)+ '&' + r'\\\\ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_median(scale_height_dist_df, subtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ages_simulations=[] \n",
    "for model in [ 'baraffe2003', 'saumon2008','marley2019', 'phillips2020']:\n",
    "    all_ages_simulations.append(age_dictionaries[model][['age', 'spt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ages_sim_df=pd.concat(all_ages_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ['baraffe2003', 'saumon2008','marley2019', 'phillips2020']:\n",
    "    for subtype in [ 'M7-L0','L0-L5', 'L5-T0', 'T0-T5', 'T5-Y0']:\n",
    "        dfn=age_dictionaries[model].replace('T5-T9', 'T5-Y0')\n",
    "        x=dfn[dfn.subtype ==subtype].age.values\n",
    "        y=age_distdf_aumer[model][subtype]\n",
    "        yx=age_distdf_just[model][subtype]\n",
    "        #fig, ax=plt.subplots()\n",
    "        #h=plt.hist(x, density=True)\n",
    "        #h=plt.hist(y, density=True)\n",
    "        if len(y)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print (model, subtype)\n",
    "            pprint(stats.ks_2samp(x, y, mode='asymp', alternative='two-sided'))\n",
    "            pprint(stats.ks_2samp(x, yx, mode='asymp', alternative='two-sided'))\n",
    "            #print (stats.anderson_ksamp(np.array([np.random.choice(x, 100),\\\n",
    "            #                                      np.random.choice(y, 100)])))\n",
    "    print ('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
